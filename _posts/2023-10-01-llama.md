---
title: "אנטרופיק: AI חוקתי, מניקור ומה שביניהם 🤖"
author: SemSis 
date: 2023-11-01 00:34:00 +0800
categories: [Anthropic, GPT]
tags: [LLMs]
---

## רקע
<div dir="rtl">

הפעם נעסוק בהרצה של Llama 2, משפחת מודלי שפה שפותחו על ידי חברת מטא.
המודלים זמינים בגדלים שונים החל מ-7 מיליארד פרמטרים ועד 70.


עבור הרצה של המודל הקטן ביותר - נדרש זכרון של 28 ג׳יגה (?). הגודל מייצג ?? פרמטרים שכל אחד מיוצג בזכרון ב-32 ביט.

על מנת להקטין את צריכת הזיכרון וזמן הריצה, נדרש להשתמש בטריקים לדחיסת המודל בזכרון. קוונטיזציה היא שיטה לאופטימיזציה של ייצוג בזכרון. במקרה שלנו - נרצה להמיר את הייצוג של פרמטרי המודל מ-32 ביט ל-4.

קוונטיזציה עוזרת בכך שמודל ה- 28 ג׳יגה כעת ניתן לטעון בקלות לזיכרון ה- RAM, וגם מסייע ב- inference time 
</div>


## איך זה נראה בפועל?
<div dir="rtl">
[1] בשלב הראשון נצטרך לקבל רישיון ל- LLama, אחרי שיש לנו token כזה.
</div>

```python
from torch import cuda


model_id = 'meta-llama/Llama-2-13b-chat-hf'
device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'


print(device)
```


## הטייקים של Semantic Sisters

נראה שמדובר במודל שנותן תוצרים ברמת איכות גבוהה והיה קל לשימוש
המודל אמנם בטיחותי, אבל עדיין לוקה בסטריאוטיפיות. אנחנו היינו מוסיפות לחוקה כמה תיקונים בנושא הזה

## רפרנסים

לינק לסקירה שלנו בפייסבוק

מאמר של חברת Anthropic על Constitutional AI

https://arxiv.org/pdf/2212.08073.pdf

